{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec75449-46fb-43f4-add2-bfd3938076b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24115e14-c0ce-49c3-b6c6-6aabcdab743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\vishn\\Downloads\\drive-download-20241028T085815Z-001\\dataset1.xlsx\")\n",
    "print (df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84c89c7-eb39-46dd-ba51-6ce2e8f2c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d50b087-f609-41ca-acd5-18ec152bf426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5115e7-f845-4ee5-a832-e6078f6ad967",
   "metadata": {},
   "source": [
    "## 1.Calculate mean, median, and standard deviation for 'age' and 'hours-per-week'##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6078acc-fcbe-4615-9cef-9df0632d7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate mean, median, and standard deviation for 'age' and 'hours-per-week'\n",
    "age_mean = df['age'].mean()\n",
    "age_median = df['age'].median()\n",
    "age_std = df['age'].std()\n",
    "\n",
    "hours_mean = df['hours-per-week'].mean()\n",
    "hours_median = df['hours-per-week'].median()\n",
    "hours_std = df['hours-per-week'].std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1712c3-c88c-4c54-91bf-5e6fc8db364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "results = {\n",
    "    'Age': {\n",
    "        'Mean': age_mean,\n",
    "        'Median': age_median,\n",
    "        'Standard Deviation': age_std\n",
    "    },\n",
    "    'Hours per Week': {\n",
    "        'Mean': hours_mean,\n",
    "        'Median': hours_median,\n",
    "        'Standard Deviation': hours_std\n",
    "    }\n",
    "}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec5e92-a8c7-4cd5-93f3-8d2450f609d9",
   "metadata": {},
   "source": [
    "# 2.Find the distribution of individuals across different \"workclass.\" Which workclass category is the most common?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421cfb4c-24d4-491e-9b41-3e8fe9f5025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "workclass_distribution = df['workclass'].value_counts()\n",
    "\n",
    "# Identify the most common workclass category\n",
    "most_common_workclass = workclass_distribution.idxmax()\n",
    "most_common_count = workclass_distribution.max()\n",
    "\n",
    "# Display the results\n",
    "results = {\n",
    "    'Workclass Distribution': workclass_distribution,\n",
    "    'Most Common Workclass': {\n",
    "        'Category': most_common_workclass,\n",
    "        'Count': most_common_count\n",
    "    }\n",
    "}\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f42789-fac7-4424-a2b8-6870388520f8",
   "metadata": {},
   "source": [
    "## 4. How many unique \"native-country\" values are there in the dataset? Which country has the most individuals represented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2183482-a183-416a-ad6b-9d410f50e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of unique values in the 'native-country' column\n",
    "unique_countries_count = df['native-country'].nunique()  \n",
    "\n",
    "# Find the country with the most individuals represented\n",
    "most_represented_country = df['native-country'].value_counts().idxmax()  \n",
    "\n",
    "# Display the results\n",
    "print(f\"Number of unique native countries: {unique_countries_count}\")\n",
    "print(f\"Country with the most individuals represented: {most_represented_country}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084b70e9-9673-45e5-a0f4-d403dcd71d59",
   "metadata": {},
   "source": [
    "## 10. Create a bar chart showing the number of individuals in each \"workclass\" category. Which workclass has the highest representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdfa466-3680-4ce0-9c45-6a5110106979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count the number of individuals in each 'workclass' category\n",
    "workclass_counts = df['workclass'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))  \n",
    "workclass_counts.plot(kind='bar', color='skyblue')  \n",
    "plt.title('Number of Individuals in Each Workclass Category')  \n",
    "plt.xlabel('Workclass')  \n",
    "plt.ylabel('Number of Individuals')  \n",
    "plt.xticks(rotation=45)  \n",
    "plt.show()  \n",
    "\n",
    "# Identify the workclass with the highest representation\n",
    "highest_represented_workclass = workclass_counts.idxmax()  \n",
    "print(f\"Workclass with the highest representation: {highest_represented_workclass}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc12e4b3-0296-4853-8048-4c7a43299666",
   "metadata": {},
   "source": [
    "\t##3.Analyze the frequency distribution of \"education\" levels. What is the most common education level, and how does it correlate with \"salary\" (<=50K or >50K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2657af1b-cc56-4012-8f25-6279b02ae204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the frequency of each education level\n",
    "education_counts = df['education'].value_counts()\n",
    "\n",
    "# Display the frequency distribution\n",
    "print(\"Frequency distribution of education levels:\")\n",
    "print(education_counts)\n",
    "\n",
    "# Identify the most common education level\n",
    "most_common_education = education_counts.idxmax()\n",
    "print(f\"\\nMost common education level: {most_common_education}\")\n",
    "\n",
    "\n",
    "salary_distribution = df.groupby(['education', 'salary']).size().unstack()  # Create a contingency table\n",
    "\n",
    "# Display the salary distribution by education level\n",
    "print(\"\\nSalary distribution by education level:\")\n",
    "print(salary_distribution)\n",
    "\n",
    "# Create a bar chart to visualize the correlation\n",
    "salary_distribution.plot(kind='bar', stacked=True, figsize=(10, 6), color=['lightblue', 'salmon'])\n",
    "plt.title('Salary Distribution by Education Level')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Number of Individuals')\n",
    "plt.xticks(rotation=45)  \n",
    "plt.legend(title='Salary', labels=['<=50K', '>50K'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671e361-4156-455f-8ef5-e378f5347d65",
   "metadata": {},
   "source": [
    " ## 5 Create a scatter plot of \"capital-gain\" vs. \"capital-loss,\" color-coded by \"salary.\" What does the plot reveal about the relationship between capital gains, capital losses, and income?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8341ad-e93b-4a00-a968-9b731d903004",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Question 2 : Telecom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae56ba5-af0b-4eb8-817f-cd3d68b9e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\vishn\\Downloads\\drive-download-20241028T085815Z-001\\dataset2.xlsx\")\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea5e36d-a49a-4a99-9e48-54db5054319d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e420ad-1634-45a0-8db3-dbedf8eac843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545274fa-5d63-4842-b8e8-0632723b035b",
   "metadata": {},
   "source": [
    "## \tData Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb87a32-c5f8-46b7-8f76-1c72bf7a1d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc50166-81f1-449c-b775-5598ed6a9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98de1d7-a8f2-42e7-89fb-3586c9a4caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2cee50-dad3-4622-86a6-13812d41ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifly missing values\n",
    "missing_values =df.isnull().sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6da3f3-0776-4868-90d5-6cc4f7a915cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d7c20-aa36-45b1-8d5e-5448d7be4a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Preprocessing\n",
    "\n",
    "# 1.1 Handling Missing Values (if any)\n",
    "# Check for missing values in each column\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ec7f0-4618-42c0-908c-3416de540d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Simple imputation \n",
    "for column in df.columns:\n",
    "    if df[column].dtype in ['float64', 'int64'] and missing_values[column] > 0 :\n",
    "      df[column] = df[column].fillna(df[column].mean()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ee2d6-d028-4528-8b60-410a7bb1767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1.2 Encoding Categorical Features\n",
    "categorical_cols = ['State', 'International plan', 'Voice mail plan']  \n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c4a773-6930-4114-921d-e272bc3576d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e3fd3-efa4-4cca-afd9-54496a145c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad99224-2d40-46ff-a7bd-8af40197c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Feature Scaling\n",
    "# Separate features (X) and target variable (y)\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a6ce58-ec7c-4493-b835-b568fcaa13dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Data Splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a25b5b5-f302-4948-b86b-7ec20b068283",
   "metadata": {},
   "source": [
    "## Model Selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550b6553-b3cc-419b-88be-2792c57e711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the models\n",
    "logistic_regression = LogisticRegression(max_iter=1000) # Increased max_iter\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "gradient_boosting = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Train the models\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "random_forest.fit(X_train, y_train)\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_lr = logistic_regression.predict(X_test)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "y_pred_gb = gradient_boosting.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "print(\"Logistic Regression:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "\n",
    "print(\"\\nGradient Boosting:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(classification_report(y_test, y_pred_gb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ed4bd9-d109-4b12-8711-adfc5b3a5fc5",
   "metadata": {},
   "source": [
    "## 4Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825b8a6-7b81-43e2-8fda-b4f25ec5dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate ROC AUC scores\n",
    "roc_auc_lr = roc_auc_score(y_test, logistic_regression.predict_proba(X_test)[:, 1])\n",
    "roc_auc_rf = roc_auc_score(y_test, random_forest.predict_proba(X_test)[:, 1])\n",
    "roc_auc_gb = roc_auc_score(y_test, gradient_boosting.predict_proba(X_test)[:, 1])\n",
    "\n",
    "\n",
    "print(\"\\nROC AUC Scores:\")\n",
    "print(\"Logistic Regression:\", roc_auc_lr)\n",
    "print(\"Random Forest:\", roc_auc_rf)\n",
    "print(\"Gradient Boosting:\", roc_auc_gb)\n",
    "\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, logistic_regression.predict_proba(X_test)[:, 1])\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, random_forest.predict_proba(X_test)[:, 1])\n",
    "fpr_gb, tpr_gb, _ = roc_curve(y_test, gradient_boosting.predict_proba(X_test)[:, 1])\n",
    "\n",
    "\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.2f})')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f})')\n",
    "plt.plot(fpr_gb, tpr_gb, label=f'Gradient Boosting (AUC = {roc_auc_gb:.2f})')\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad97e68-2cef-48a0-b6b8-df8f7caadef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  4.Model Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba974df-9510-41bc-b59a-6405f65d06e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "# Save the trained models and scalers\n",
    "model_filename = 'trained_models.pkl'\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump({\n",
    "        'logistic_regression': logistic_regression,\n",
    "        'random_forest': random_forest,\n",
    "        'gradient_boosting': gradient_boosting,\n",
    "        'scaler': scaler, \n",
    "        'label_encoders': label_encoders\n",
    "    }, file)\n",
    "\n",
    "print(f\"Trained models and preprocessing components saved to {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16573b7-a6f0-4b8b-8d68-d8bb2af484a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
